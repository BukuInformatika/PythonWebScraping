\section{Web Scraping}
\subsection{Apa Itu Web Scraping?}

Secara teori, \textit{web scraping} adalah praktik mengumpulkan data melalui cara apa pun selain program yang berinteraksi dengan API (atau melalui manusia menggunakan browser). Cara ini paling umum dilakukan dengan menulis program otomatis yang membutuhkan server web, meminta data (biasanya dalam bentuk HTML, Json, dan file lain yang terdiri dari halaman web), dan kemudian mem-\textit{parsing} data tersebut untuk mengekstrak informasi yang diperlukan. Sedangkan pada praktiknya,\textit{web scraping} mencakup beragam teknik dan teknologi pemrograman, seperti analisis data dan keamanan informasi.

\subsection{Mengapa Web Scraping?}

Ada banyak alasan mengapa web scraping semakin dibutuhkan pada abad ke 21 ini. Dengan semakin berkembangnya data, jumlah data yang tersedia mungkin sudah tidak terhitung lagi. Bayangkan jika kita membutuhkan data-data itu lalu Anda harus mengumpulkan dan menyimpan jutaan data dalam satu file. Teknik web scraping bisa membantu kita untuk mengumpulkan data dengan lebih cepat dan otomatis, semua akan berjalan lancar selama server masih berfungsi.

Efisiennya teknik web scraping ini juga membantu proses pengambilan data demi kebutuhan analisa. Karena web scraping membantu mengumpulkan semua data tanpa terlewat. Dengan begitu, Anda akan mendapat insight yang bernilai dengan lebih cepat. Kita juga bisa memanfaatkan web scraping untuk mengumpulkan data lain yang penting.

Selain di dunia bisnis, di dunia seni pun, web scraping telah diterapkan untuk proyek 2006 “We Feel Fine” oleh Jonathan Harris dan Sep Kamvar, men-\textit{scrap} berbagai situs blog berbahasa Inggris untuk frasa yang dimulai dengan “I feel” atau “I am feeling” dan dengan data tersebut, bisa diolah menjadi visualisasi data bagaimana perasaan orang-orang di dunia setiap harinya. Terlepas dari bidang apapun, hampir selalu ada cara\textit{web scraping} dapat memandu bisnis lebih efektif dan meningkatkan produktivitas.

\subsection{Teknik web scraping}
Karena web scraping sudah mulai familiar, maka banyak orang yang melakukannya karena beberapa kemudahan yang telah dijabarkan diatas, ada beberapa teknik automasi yang bisa kita lakukan untuk melakukan web scraping.

\subsubsection{Parsing HTML}

Parsing HTML adalah salah satu teknik yang paling banyak digunakan dalam web parsing atau web scraping. Biasanya parsing HTML dilakukan menggunakan JavaScript dan menarget halaman HTML linear dan nested. Metode ini dapat mengidentifikasi script HTML dari websia. Script ini juga kemudian digunakan untuk mengekstraksi text, links, dan data.

\subsubsection{Parsing DOM}

\textit{Content, style, dan XML structure} didefinisikan dalam Document Object Model atau yang biasa disebut DOM. Beberapa programmer yang ingin mengetahui cara kerja sebuah internal web dan ingin mengekstrak \textit{script} yang berjalan di dalamnya akan lebih memilih untuk melakukan \textit{web scraping} melalui parsing DOM. Node dikumpulkan terlebih dahulu menggunakan DOM yang terlah diparsing dan XPath membantu mempermudah proses scraping.

\subsubsection{XPath}

\textit{XML Path Language} atau lebih familiar dengan istilah XPath adalah bahasa \textit{query} yang bekerja pada dokumen Extensible Markup Language atau biasa disebut XML. Dokumen XML biasa disusun dengan \textit{tree structure}, XPath bisa digunakan untuk menganalisa struktur dokumen dengan memilih nodes berdasarkan parameter yang telah tersedia. XPath juga lazim digunakan bersamaan dengan DOM parsing dalam mengesktrasi seluruh halaman website.

\subsubsection{Google Docs}

Salah satu produk Google yaitu Google Sheets juga ternyata bisa dipakai sebagai salah satu alat scraping,, dan ini adalah salah satu alat scraping yang cukup popoler karena cara penggunaannya yang tidak rumit dan tidak membutuhkan keahlian khusus. Pada Google Sheets sendiri, kita bisa memanfaatkan fungsi IMPORTXML untuk melakukan scraping data dari website. Selain itu, juga bisa menggunakan command ini untuk melihat apakah sebuah website aman dari tindakan scraping atau tidak.
